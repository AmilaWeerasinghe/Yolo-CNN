{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Custom YOLO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPY0IpoEoidQ4f1TW9p7VWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmilaWeerasinghe/Yolo-CNN/blob/master/Copy_of_Custom_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyGzPIAl1KPV"
      },
      "source": [
        "import numpy as np\r\n",
        "np.random.seed(1)\r\n",
        "image=np.random.randn(1, 256, 256, 3) #h256X256 image\r\n",
        "W1=np.random.randn(3, 3, 3, 32)\r\n",
        "b1=np.random.randn(1, 1, 1, 32)\r\n",
        "W2=np.random.randn(3, 3, 32, 64)\r\n",
        "b2=np.random.randn(1, 1, 1, 64)\r\n",
        "W3=np.random.randn(3, 3, 64, 128)\r\n",
        "b3=np.random.randn(1, 1, 1, 128)\r\n",
        "hparameters1 = {\"pad\" : 129,\"stride\": 2}\r\n",
        "hparameters3 = {\"pad\" : 65,\"stride\": 2}\r\n",
        "hparameters2 = {\"stride\" : 2, \"f\": 2}\r\n",
        "hparameters4 = {\"stride\" : 2, \"f\": 2}\r\n",
        "hparameters5 = {\"pad\" : 32,\"stride\": 2}\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnTC7QEOf-5J"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "K-REjdbQf_lG",
        "outputId": "e24a5088-71c3-451b-b94b-fb0aa73ba31e"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "def softmax(Z):\r\n",
        "    \"\"\"\r\n",
        "    Softmax activation function, vectorized version (array Z).\r\n",
        "    Args:\r\n",
        "        Z (ndarray): numpy array of any shape, output of the linear layer\r\n",
        "    \"\"\"\r\n",
        "    Z_exp = np.exp(Z)\r\n",
        "    A = Z_exp / np.sum(Z_exp, axis=1,keepdims=True)\r\n",
        "\r\n",
        "    assert (A.shape == Z.shape)\r\n",
        "\r\n",
        "    return A\r\n",
        "\r\n",
        "def relu(Z):\r\n",
        "    \"\"\"\r\n",
        "    ReLU activation function, vectorized version (array Z).\r\n",
        "    Args:\r\n",
        "        Z (ndarray): numpy array of any shape, output of the linear layer\r\n",
        "    Returns:\r\n",
        "        A (ndarray): post-activation output of relu(Z), same shape as Z\r\n",
        "    \"\"\"\r\n",
        "    A = np.maximum(0, Z)\r\n",
        "\r\n",
        "    assert (A.shape == Z.shape)\r\n",
        "\r\n",
        "    return A\r\n",
        "\r\n",
        "\r\n",
        "def zero_pad(X, pad):\r\n",
        "    \"\"\"\r\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image,\r\n",
        "    as illustrated in Figure 1.\r\n",
        "\r\n",
        "    Argument:\r\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\r\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\r\n",
        "    \"\"\"\r\n",
        "    X_pad =np.pad(X, ((0,0),(pad,pad),(pad,pad),(0,0)), mode='constant', constant_values = (0,0))\r\n",
        "\r\n",
        "\r\n",
        "    return X_pad\r\n",
        "\r\n",
        "def conv_single_step(a_slice_prev, W, b):\r\n",
        "    \"\"\"\r\n",
        "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation\r\n",
        "    of the previous layer.\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\r\n",
        "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\r\n",
        "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\r\n",
        "    s = a_slice_prev*W\r\n",
        "    # Sum over all entries of the volume s.\r\n",
        "    Z = s.sum()\r\n",
        "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\r\n",
        "    Z = Z+float(b)\r\n",
        "\r\n",
        "\r\n",
        "    return Z\r\n",
        "\r\n",
        "def conv_forward(A_prev, W, b, hparameters):\r\n",
        "    \"\"\"\r\n",
        "    Implements the forward propagation for a convolution function\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    A_prev -- output activations of the previous layer,\r\n",
        "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\r\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\r\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\r\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\r\n",
        "    cache -- cache of values needed for the conv_backward() function\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Retrieve dimensions from A_prev's shape\r\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\r\n",
        "\r\n",
        "    # Retrieve dimensions from W's shape\r\n",
        "    (f, f, n_C_prev, n_C) = W.shape\r\n",
        "\r\n",
        "    # Retrieve information from \"hparameters\"\r\n",
        "    stride = hparameters[\"stride\"]\r\n",
        "    pad = hparameters[\"pad\"]\r\n",
        "\r\n",
        "    # Compute the dimensions of the CONV output volume using the formula given above.\r\n",
        "    # Hint: use int() to apply the 'floor' operation.\r\n",
        "    n_H = int((n_H_prev-f+2*pad)/stride+1)\r\n",
        "    n_W = int((n_W_prev-f+2*pad)/stride+1)\r\n",
        "\r\n",
        "    # Initialize the output volume Z with zeros.\r\n",
        "    Z = np.zeros((m,n_H,n_W,n_C))\r\n",
        "\r\n",
        "    # Create A_prev_pad by padding A_prev\r\n",
        "    A_prev_pad =zero_pad(A_prev, pad)\r\n",
        "\r\n",
        "    for i in range(m):               # loop over the batch of training examples\r\n",
        "        a_prev_pad = A_prev_pad[i]               # Select ith training example's padded activation\r\n",
        "        for h in range(n_H):           # loop over vertical axis of the output volume\r\n",
        "            vert_start = h*stride\r\n",
        "            vert_end = vert_start+f\r\n",
        "\r\n",
        "            for w in range(n_W):       # loop over horizontal axis of the output volume\r\n",
        "                #Find the horizontal start and end of the current \"slice\" (≈2 lines)\r\n",
        "                horiz_start = w*stride\r\n",
        "                horiz_end = horiz_start+f\r\n",
        "\r\n",
        "        #iterate over the filters\r\n",
        "                for c in range(n_C):   # loop over channels (= #filters) of the output volume\r\n",
        "\r\n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\r\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\r\n",
        "\r\n",
        "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\r\n",
        "                    weights = W[:,:,:,c]\r\n",
        "                    biases = b[:,:,:,c]\r\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev,weights,biases)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    # Making sure your output shape is correct\r\n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\r\n",
        "\r\n",
        "    # Save information in \"cache\" for the backprop\r\n",
        "    #cache = (A_prev, W, b, hparameters)\r\n",
        "\r\n",
        "    return Z#, cache\r\n",
        "\r\n",
        "# GRADED FUNCTION: pool_forward\r\n",
        "\r\n",
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\r\n",
        "    \"\"\"\r\n",
        "    Implements the forward pass of the pooling layer\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\r\n",
        "    hparameters -- python dictionary containing \"f\" and \"stride\"\r\n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\r\n",
        "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Retrieve dimensions from the input shape\r\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\r\n",
        "\r\n",
        "    # Retrieve hyperparameters from \"hparameters\"\r\n",
        "    f = hparameters[\"f\"]\r\n",
        "    stride = hparameters[\"stride\"]\r\n",
        "\r\n",
        "    # Define the dimensions of the output\r\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\r\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\r\n",
        "    n_C = n_C_prev\r\n",
        "\r\n",
        "    # Initialize output matrix A\r\n",
        "    A = np.zeros((m, n_H, n_W, n_C))\r\n",
        "\r\n",
        "    for i in range(m):                         # loop over the training examples\r\n",
        "        for h in range(n_H):                     # loop on the vertical axis of the output volume\r\n",
        "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\r\n",
        "            vert_start = h*stride\r\n",
        "            vert_end = vert_start+f\r\n",
        "\r\n",
        "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\r\n",
        "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\r\n",
        "                horiz_start = w*stride\r\n",
        "                horiz_end = horiz_start+f\r\n",
        "\r\n",
        "                for c in range (n_C):            # loop over the channels of the output volume\r\n",
        "\r\n",
        "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\r\n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\r\n",
        "\r\n",
        "                    # Compute the pooling operation on the slice.\r\n",
        "                    # Use an if statement to differentiate the modes.\r\n",
        "                    # Use np.max and np.mean.\r\n",
        "                    if mode == \"max\":\r\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\r\n",
        "                    elif mode == \"average\":\r\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\r\n",
        "    #cache = (A_prev, hparameters)\r\n",
        "\r\n",
        "    # Making sure your output shape is correct\r\n",
        "    #assert(A.shape == (m, n_H, n_W, n_C))\r\n",
        "\r\n",
        "    return A#, cache\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "#test\r\n",
        "np.random.seed(1)\r\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\r\n",
        "hparameters = {\"stride\" : 1, \"f\": 3}\r\n",
        "\r\n",
        "A= pool_forward(A_prev, hparameters)\r\n",
        "print(\"mode = max\")\r\n",
        "print(\"A.shape = \" + str(A.shape))\r\n",
        "\r\n",
        "\r\n",
        "#softmax test\r\n",
        "\r\n",
        "x = np.array([\r\n",
        "    [9, 2, 5, 0, 0],\r\n",
        "    [7, 5, 0, 0 ,0]])\r\n",
        "print(\"softmax(x) = \" + str(softmax(x)))\r\n",
        "\"\"\"\r\n",
        "\"\"\"\r\n",
        "expected output\r\n",
        "[\r\n",
        " [  9.80897665e-01   8.94462891e-04   1.79657674e-02   1.21052389e-04 1.21052389e-04]\r\n",
        " [  8.78679856e-01   1.18916387e-01   8.01252314e-04   8.01252314e-04 8.01252314e-04]\r\n",
        "]\r\n",
        "\r\n",
        "\"\"\"\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nexpected output\\n[\\n [  9.80897665e-01   8.94462891e-04   1.79657674e-02   1.21052389e-04 1.21052389e-04]\\n [  8.78679856e-01   1.18916387e-01   8.01252314e-04   8.01252314e-04 8.01252314e-04]\\n]\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYcs4UDGgCpk",
        "outputId": "0fa20a9c-6bce-47fb-ce9d-709a687f2aa4"
      },
      "source": [
        "#YOLO conv net\r\n",
        "import time\r\n",
        "#from yolo import conv_forward,pool_forward\r\n",
        "#from weights import image,W1,b1,W2,b2,W3,b3,hparameters1,hparameters2,hparameters3,hparameters4,hparameters5\r\n",
        "tic = time.process_time()\r\n",
        "out1=conv_forward(image, W1, b1, hparameters1) #3x3 s-1 pad-1 filters 16 activation-leaky\r\n",
        "out2=pool_forward(out1, hparameters2, mode = \"max\") #2x2 s-2\r\n",
        "out3=conv_forward(out2, W2, b2, hparameters3) #3x3 s-1 pad-1 filters 32 activation-leaky\r\n",
        "out4=pool_forward(out3, hparameters4, mode = \"max\") #2x2 s-2\r\n",
        "out5=conv_forward(out4, W3, b3, hparameters5) #3x3 s-1 pad-1 filters 32 activation-leaky\r\n",
        "toc = time.process_time()\r\n",
        "print (\"Computation time = \" + str(1000*(toc - tic)) + \"ms\")\r\n",
        "out5.shape\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computation time = 29203.033650999998ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 63, 63, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}